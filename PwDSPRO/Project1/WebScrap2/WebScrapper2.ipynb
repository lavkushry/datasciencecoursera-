{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b109a8e-d133-4df9-9d40-7d69cf58ab09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to video_urls.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Q1. Write a python program to extract the video URL of the first five videos.\n",
    "# Note: Save all the data scraped in the above questions in a CSV file.\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send a GET request to the webpage\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the video URLs\n",
    "video_urls = []\n",
    "for video in soup.find_all('a', {'class': 'yt-simple-endpoint style-scope ytd-playlist-video-renderer'}, limit=5):  # extract the first 5 videos\n",
    "    video_url = f\"https://www.youtube.com{video['href']}\"\n",
    "    video_urls.append(video_url)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "with open('video_urls.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Video URL\"])  # header row\n",
    "    for url in video_urls:\n",
    "        writer.writerow([url])\n",
    "\n",
    "print(\"Data saved to video_urls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cbefa98-8001-4f48-be27-5772ad549631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to video_thumbnails.csv\n"
     ]
    }
   ],
   "source": [
    "# Q2. Write a python program to extract the URL of the video thumbnails of the first five videos.\n",
    "# Note: Save all the data scraped in the above questions in a CSV file.\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send a GET request to the webpage\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the video thumbnail URLs\n",
    "video_thumbnails = []\n",
    "for video in soup.find_all('a', {'class': 'yt-simple-endpoint style-scope ytd-playlist-video-renderer'}, limit=5):  # extract the first 5 videos\n",
    "    thumbnail_url = video.find('img')['src']\n",
    "    video_thumbnails.append(thumbnail_url)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "with open('video_thumbnails.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Video Thumbnail URL\"])  # header row\n",
    "    for url in video_thumbnails:\n",
    "        writer.writerow([url])\n",
    "\n",
    "print(\"Data saved to video_thumbnails.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddc7d211-df37-4e8c-956c-2455ef0130ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to video_titles.csv\n"
     ]
    }
   ],
   "source": [
    "# Q3. Write a python program to extract the title of the first five videos.\n",
    "# Note: Save all the data scraped in the above questions in a CSV file.\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send a GET request to the webpage\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the video titles\n",
    "video_titles = []\n",
    "for video in soup.find_all('a', {'class': 'yt-simple-endpoint style-scope ytd-playlist-video-renderer'}, limit=5):  # extract the first 5 videos\n",
    "    title = video.find('span', {'class': 'ytd-playlist-video-renderer'}).text\n",
    "    video_titles.append(title)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "with open('video_titles.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Video Title\"])  # header row\n",
    "    for title in video_titles:\n",
    "        writer.writerow([title])\n",
    "\n",
    "print(\"Data saved to video_titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "841fa2af-839e-4d58-b81e-c6cd1d9c17dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to video_views.csv\n"
     ]
    }
   ],
   "source": [
    "# Q4. Write a python program to extract the number of views of the first five videos.\n",
    "# Note: Save all the data scraped in the above questions in a CSV file.\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send a GET request to the webpage\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the video views\n",
    "video_views = []\n",
    "for video in soup.find_all('a', {'class': 'yt-simple-endpoint style-scope ytd-playlist-video-renderer'}, limit=5):  # extract the first 5 videos\n",
    "    views = video.find('span', {'class': 'view-count style-scope ytd-video-view-count-renderer'}).text\n",
    "    video_views.append(views)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "with open('video_views.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Video Views\"])  # header row\n",
    "    for view in video_views:\n",
    "        writer.writerow([view])\n",
    "\n",
    "print(\"Data saved to video_views.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f478257d-31d6-46c1-beb1-42cc7418dcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to video_posting_time.csv\n"
     ]
    }
   ],
   "source": [
    "# Q5. Write a python program to extract the time of posting of video for the first five videos.\n",
    "# Note: Save all the data scraped in the above questions in a CSV file.\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send a GET request to the webpage\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the video posting time\n",
    "video_posting_time = []\n",
    "for video in soup.find_all('a', {'class': 'yt-simple-endpoint style-scope ytd-playlist-video-renderer'}, limit=5):  # extract the first 5 videos\n",
    "    time = video.find('span', {'class': 'style-scope ytd-video-meta-block'}).text.strip()  # extract the time\n",
    "    video_posting_time.append(time)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "with open('video_posting_time.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Video Posting Time\"])  # header row\n",
    "    for time in video_posting_time:\n",
    "        writer.writerow([time])\n",
    "\n",
    "print(\"Data saved to video_posting_time.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1175c99-f3af-47c5-b058-34f4f84c8a85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
